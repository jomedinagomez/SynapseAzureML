{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Importing pyspark dependencies\r\n",
        "from pyspark.sql.types import IntegerType,BooleanType,DateType,NumericType,TimestampType\r\n",
        "from pyspark.ml.feature import Binarizer, Bucketizer, QuantileDiscretizer\r\n",
        "from com.microsoft.spark.sqlanalytics.Constants import Constants\r\n",
        "import com.microsoft.spark.sqlanalytics\r\n",
        "from pyspark.sql.functions import col\r\n",
        "import pyspark.sql.functions as F\r\n",
        "\r\n",
        "# Importing mlflow libraries\r\n",
        "from mlflow.models import infer_signature, set_signature\r\n",
        "from mlflow.models.model import get_model_info\r\n",
        "import mlflow\r\n",
        "\r\n",
        "\r\n",
        "# Importing general libraries\r\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix, recall_score, roc_auc_score, classification_report\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "#AML workspace authentication using linked service\r\n",
        "from notebookutils.mssparkutils import azureML\r\n",
        "linked_service_name = \"AzureMLService1\"\r\n",
        "ws = azureML.getWorkspace(linked_service_name)\r\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri().replace(\"v2.0\",\"v1.0\"))\r\n",
        "\r\n",
        "## Importing SynapseML\r\n",
        "from synapse.ml.featurize import Featurize\r\n",
        "from synapse.ml.lightgbm import *\r\n",
        "from synapse.ml.train import ComputeModelStatistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "# Read from existing internal table\r\n",
        "df = (spark.read.synapsesql(\"synapseazuremldedicates.dbo.class_transformed_taxi_data\")).drop('cost')\r\n",
        "\r\n",
        "# Show contents of the dataframe\r\n",
        "display(df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 2.2 Split dataset in train/test using a stratified strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "train_df = df.sampleBy(\"cost_class\", fractions={0: 0.7, 1: 0.7, 2: 0.7, 3: 0.7, 4: 0.7}, seed=10)\r\n",
        "\r\n",
        "print(\"----------------------------------------------------------------------\")\r\n",
        "print(\"Printing count of train dataset\")\r\n",
        "train_df.groupBy(\"cost_class\").count().show()\r\n",
        "\r\n",
        "test_df = df.subtract(train_df)\r\n",
        "\r\n",
        "print(\"----------------------------------------------------------------------\")\r\n",
        "print(\"Printing count of test dataset\")\r\n",
        "test_df.groupBy(\"cost_class\").count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 1 - Setting up dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Define the models to be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#https://spark.apache.org/docs/latest/api/python/_modules/pyspark/ml/classification.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from synapse.ml.automl import TuneHyperparameters\r\n",
        "from synapse.ml.train import TrainClassifier\r\n",
        "from pyspark.ml.classification import (\r\n",
        "    LogisticRegression,\r\n",
        "    RandomForestClassifier,\r\n",
        "    GBTClassifier,\r\n",
        ")\r\n",
        "\r\n",
        "logReg = LogisticRegression()\r\n",
        "randForest = RandomForestClassifier()\r\n",
        "gbt = GBTClassifier()\r\n",
        "smlmodels = [logReg, randForest]\r\n",
        "mmlmodels = [TrainClassifier(model=model, labelCol=\"cost_class\") for model in smlmodels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 2 - Find the best model using AutoML\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Import SynapseML's AutoML classes from `synapse.ml.automl`. Specify the hyperparameters using the `HyperparamBuilder`. Add either `DiscreteHyperParam` or `RangeHyperParam` hyperparameters. `TuneHyperparameters` will randomly choose values from a uniform distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from synapse.ml.automl import *\r\n",
        "\r\n",
        "paramBuilder = (\r\n",
        "    HyperparamBuilder()\r\n",
        "    .addHyperparam(logReg, logReg.regParam, RangeHyperParam(0.1, 0.3))\r\n",
        "    .addHyperparam(randForest, randForest.numTrees, DiscreteHyperParam([5, 10]))\r\n",
        "    .addHyperparam(randForest, randForest.maxDepth, DiscreteHyperParam([3, 5]))\r\n",
        ")\r\n",
        "searchSpace = paramBuilder.build()\r\n",
        "# The search space is a list of params to tuples of estimator and hyperparam\r\n",
        "print(searchSpace)\r\n",
        "randomSpace = RandomSpace(searchSpace)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "bestModel = TuneHyperparameters(\r\n",
        "    evaluationMetric=\"accuracy\",\r\n",
        "    models=mmlmodels,\r\n",
        "    numFolds=5,\r\n",
        "    numRuns=len(mmlmodels) * 5,\r\n",
        "    parallelism=1,\r\n",
        "    paramSpace=randomSpace.space(),\r\n",
        "    seed=0,\r\n",
        ").fit(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "print(bestModel.getBestModelInfo())\r\n",
        "print(bestModel.getBestModel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from synapse.ml.train import ComputeModelStatistics\r\n",
        "\r\n",
        "prediction = bestModel.transform(test_df)\r\n",
        "metrics = ComputeModelStatistics().transform(prediction)\r\n",
        "metrics.limit(10).toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": []
    }
  ]
}