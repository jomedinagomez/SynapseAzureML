{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Model Training"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing pyspark dependencies\r\n",
        "from pyspark.sql.types import IntegerType,BooleanType,DateType,NumericType,TimestampType\r\n",
        "from pyspark.ml.feature import Binarizer, Bucketizer, QuantileDiscretizer\r\n",
        "from com.microsoft.spark.sqlanalytics.Constants import Constants\r\n",
        "import com.microsoft.spark.sqlanalytics\r\n",
        "from pyspark.sql.functions import col\r\n",
        "import pyspark.sql.functions as F\r\n",
        "\r\n",
        "# Importing mlflow libraries\r\n",
        "from mlflow.models import infer_signature, set_signature\r\n",
        "from mlflow.models.model import get_model_info\r\n",
        "import mlflow\r\n",
        "\r\n",
        "\r\n",
        "# Importing general libraries\r\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix, recall_score, roc_auc_score, classification_report\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "#AML workspace authentication using linked service\r\n",
        "from notebookutils.mssparkutils import azureML\r\n",
        "linked_service_name = \"AzureMLService1\"\r\n",
        "ws = azureML.getWorkspace(linked_service_name)\r\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri().replace(\"v2.0\",\"v1.0\"))\r\n",
        "\r\n",
        "## Importing SynapseML\r\n",
        "from synapse.ml.featurize import Featurize\r\n",
        "from synapse.ml.lightgbm import *\r\n",
        "from synapse.ml.train import ComputeModelStatistics"
      ],
      "outputs": [],
      "execution_count": 199,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Read from existing internal table\r\n",
        "df = (spark.read.synapsesql(\"synapseazuremldedicates.dbo.class_transformed_taxi_data\")).drop('cost')\r\n",
        "\r\n",
        "# Show contents of the dataframe\r\n",
        "display(df.head(5))"
      ],
      "outputs": [],
      "execution_count": 200,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Split dataset in train/test using a stratified strategy"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df.sampleBy(\"cost_class\", fractions={0: 0.7, 1: 0.7, 2: 0.7, 3: 0.7, 4: 0.7}, seed=10)\r\n",
        "\r\n",
        "print(\"----------------------------------------------------------------------\")\r\n",
        "print(\"Printing count of train dataset\")\r\n",
        "train_df.groupBy(\"cost_class\").count().show()\r\n",
        "\r\n",
        "test_df = df.subtract(train_df)\r\n",
        "\r\n",
        "print(\"----------------------------------------------------------------------\")\r\n",
        "print(\"Printing count of test dataset\")\r\n",
        "test_df.groupBy(\"cost_class\").count().show()"
      ],
      "outputs": [],
      "execution_count": 201,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Train featurizer"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.autolog(exclusive=False)\r\n",
        "\r\n",
        "#Set MLflow experiment.\r\n",
        "experiment_name = \"taxi-classifier-experiment\"\r\n",
        "mlflow.set_experiment(experiment_name)\r\n",
        "\r\n",
        "with mlflow.start_run(run_name=\"class_featurization\") as featurization:\r\n",
        "    feature_cols = [column for column in train_df.columns if column!=\"cost_class\"]\r\n",
        "    featurize = (Featurize()\r\n",
        "    .setOutputCol(\"features\")\r\n",
        "    .setInputCols(feature_cols)\r\n",
        "    .setOneHotEncodeCategoricals(True)\r\n",
        "    .setNumFeatures(4096))\r\n",
        "    featurizer_model = featurize.fit(train_df)\r\n",
        "    train_df_trans = featurizer_model.transform(train_df)\r\n",
        "    test_df_trans = featurizer_model.transform(test_df)\r\n",
        "\r\n",
        "    mlflow.end_run()\r\n",
        "\r\n",
        "## Registering featurizer\r\n",
        "model_name = 'featurizer'\r\n",
        "model_uri = f\"runs:/{featurization.info.run_id}/model\"\r\n",
        "mlflow.register_model(model_uri=model_uri, name=model_name)"
      ],
      "outputs": [],
      "execution_count": 203,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Train classifier"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.autolog(exclusive=False)\r\n",
        "\r\n",
        "#Set MLflow experiment.\r\n",
        "experiment_name = \"taxi-classifier-experiment\"\r\n",
        "mlflow.set_experiment(experiment_name)\r\n",
        "\r\n",
        "with mlflow.start_run(run_name=\"class_training\") as training:\r\n",
        "\r\n",
        "    lightgbm_classifier = (LightGBMClassifier()\r\n",
        "            .setFeaturesCol(\"features\")\r\n",
        "            .setRawPredictionCol(\"rawPrediction\")\r\n",
        "            .setDefaultListenPort(12402)\r\n",
        "            .setNumLeaves(5)\r\n",
        "            .setNumIterations(10)\r\n",
        "            .setObjective(\"multiclass\")\r\n",
        "            .setLabelCol(\"cost_class\")\r\n",
        "            .setLeafPredictionCol(\"leafPrediction\")\r\n",
        "            .setFeaturesShapCol(\"featuresShap\"))\r\n",
        "\r\n",
        "    lightgbm_model = lightgbm_classifier.fit(train_df_trans)\r\n",
        "\r\n",
        "    # Use mlflow.spark.save_model to save the model to your path\r\n",
        "    mlflow.spark.save_model(lightgbm_model, \"lightgbm_model\")\r\n",
        "    # Use mlflow.spark.log_model to log the model if you have a connected mlflow service\r\n",
        "    mlflow.spark.log_model(lightgbm_model, \"lightgbm_model\")\r\n",
        "\r\n",
        "    # Use mlflow.spark.load_model to load model back as PipelineModel and apply transform\r\n",
        "    predictions = lightgbm_model.transform(train_df_trans)\r\n",
        "    metrics = ComputeModelStatistics(evaluationMetric=\"classification\", labelCol='cost_class', scoredLabelsCol='prediction').transform(predictions).collect()\r\n",
        "    mlflow.log_metric(\"Train accuracy\", metrics[0]['accuracy'])\r\n",
        "    mlflow.log_metric(\"Train precision\", metrics[0]['precision'])\r\n",
        "    mlflow.log_metric(\"Train recall\", metrics[0]['recall'])\r\n",
        "    mlflow.log_metric(\"Train macro_averaged_precision\", metrics[0]['macro_averaged_precision'])\r\n",
        "    mlflow.log_metric(\"Train macro_averaged_recall\", metrics[0]['macro_averaged_recall'])\r\n",
        "    print(metrics)\r\n",
        "\r\n",
        "    predictions = lightgbm_model.transform(test_df_trans)\r\n",
        "    metrics = ComputeModelStatistics(evaluationMetric=\"classification\", labelCol='cost_class', scoredLabelsCol='prediction').transform(predictions).collect()\r\n",
        "    mlflow.log_metric(\"Test accuracy\", metrics[0]['accuracy'])\r\n",
        "    mlflow.log_metric(\"Test precision\", metrics[0]['precision'])\r\n",
        "    mlflow.log_metric(\"Test recall\", metrics[0]['recall'])\r\n",
        "    mlflow.log_metric(\"Test macro_averaged_precision\", metrics[0]['macro_averaged_precision'])\r\n",
        "    mlflow.log_metric(\"Test macro_averaged_recall\", metrics[0]['macro_averaged_recall'])\r\n",
        "    print(metrics)\r\n",
        "\r\n",
        "    mlflow.end_run()\r\n",
        "\r\n",
        "## Registering Classifier \r\n",
        "model_name = 'classification_demo'\r\n",
        "model_uri = f\"runs:/{training.info.run_id}/lightgbm_model\"\r\n",
        "mlflow.register_model(model_uri=model_uri, name=model_name)"
      ],
      "outputs": [],
      "execution_count": 280,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Testing models"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4.1 Testing model from run folder"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### --------------------------------------------------------------------------- ###\r\n",
        "model_name = 'featurizer'\r\n",
        "# Search registered models for the \r\n",
        "for model in mlflow.search_registered_models():\r\n",
        "    if model.name == model_name:\r\n",
        "        latest_version_run_id = model.latest_versions[0].run_id\r\n",
        "        model_found = True\r\n",
        "        break\r\n",
        "\r\n",
        "# load model from Azure Machine Learning\r\n",
        "run_id = latest_version_run_id\r\n",
        "artifact_path = \"model\"\r\n",
        "model_uri = f\"runs:/{run_id}/{artifact_path}\"\r\n",
        "featurizer = mlflow.pyfunc.load_model(model_uri)\r\n",
        "\r\n",
        "### --------------------------------------------------------------------------- ###\r\n",
        "\r\n",
        "model_name = 'classification_demo'\r\n",
        "# Search registered models for the \r\n",
        "for model in mlflow.search_registered_models():\r\n",
        "    if model.name == model_name:\r\n",
        "        latest_version_run_id = model.latest_versions[0].run_id\r\n",
        "        model_found = True\r\n",
        "        break\r\n",
        "\r\n",
        "# load model from Azure Machine Learning\r\n",
        "run_id = latest_version_run_id\r\n",
        "artifact_path = \"lightgbm_model\"\r\n",
        "model_uri = f\"runs:/{run_id}/{artifact_path}\"\r\n",
        "model = mlflow.pyfunc.load_model(model_uri)\r\n",
        "\r\n",
        "### --------------------------------------------------------------------------- ###\r\n",
        "\r\n",
        "test_df_trans = featurizer_model.transform(test_df)\r\n",
        "pandas_test_df = test_df_trans.toPandas()\r\n",
        "\r\n",
        "# testing model\r\n",
        "test_predictions = model.predict(pandas_test_df.head())\r\n",
        "print(test_predictions)"
      ],
      "outputs": [],
      "execution_count": 288,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4.2 Testing model from model registry using pyfunc"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = mlflow.pyfunc.load_model(model_uri=f\"models:/classification_demo/latest\")\r\n",
        "\r\n",
        "test_predictions = model.predict(pandas_test_df.head())\r\n",
        "print(test_predictions)"
      ],
      "outputs": [],
      "execution_count": 289,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.4.3 Testing model from model registry using spark"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark_model = mlflow.spark.load_model(model_uri=f\"models:/classification_demo/latest\")\r\n",
        "display(spark_model.transform(test_df_trans))"
      ],
      "outputs": [],
      "execution_count": 290,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}